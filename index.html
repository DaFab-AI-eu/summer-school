<!DOCTYPE html>
<html lang="en">
<head>
<!--
Per3S - 9ème édition
http://www.templatemo.com/tm-486-new-event
-->
<title>Per3S - Workshop on High Performance Storage</title>
<meta name="description" content="">
<meta name="author" content="">
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=Edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="css/bootstrap.min.css">
<link rel="stylesheet" href="css/animate.css">
<link rel="stylesheet" href="css/font-awesome.min.css">
<link rel="stylesheet" href="css/owl.theme.css">
<link rel="stylesheet" href="css/owl.carousel.css">

<!-- Main css -->
<link rel="stylesheet" href="css/style.css">

<!-- Google Font -->
<link href='https://fonts.googleapis.com/css?family=Poppins:400,500,600' rel='stylesheet' type='text/css'>

<style>
mark { 
 background-color:rgba(242,84,95,0.5);
  color: white;
}
</style>
</head>
<body data-spy="scroll" data-offset="50" data-target=".navbar-collapse">

<!-- =========================
     PRE LOADER       
============================== -->
<div class="preloader">

	<div class="sk-rotating-plane"></div>

</div>


<!-- =========================
     NAVIGATION LINKS     
============================== -->
<div class="navbar navbar-fixed-top custom-navbar" role="navigation">
	<div class="container">

		<!-- navbar header -->
		<div class="navbar-header">
			<button class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
				<span class="icon icon-bar"></span>
				<span class="icon icon-bar"></span>
				<span class="icon icon-bar"></span>
			</button>
			<a href="#" class="navbar-brand">Per3S</a>
		</div>

        <div class="collapse navbar-collapse">
			<ul class="nav navbar-nav navbar-right">
				<li><a href="#intro" class="smoothScroll">Introduction</a></li>
				<li><a href="#presentation" class="smoothScroll">Presentation</a></li>
				<li><a href="#programme" class="smoothScroll">Program</a></li>
				<li><a href="#organisateurs" class="smoothScroll">Organisation</a></li>
				<li><a href="#registration" class="smoothScroll">Registration</a></li>
				<li><a href="#venir" class="smoothScroll">Venue</a></li>
				<li><a href="#sponsors" class="smoothScroll">Sponsors</a></li>
				<li><a href="#contact" class="smoothScroll">Previous Edition</a></li>
			</ul>

		</div>

	</div>
</div>


<!-- =========================
    INTRO SECTION   
============================== -->
<section id="intro" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="col-md-12 col-sm-12">
				<h3 class="wow bounceIn" data-wow-delay="0.9s"><mark>Join us May 23 2025 at "Maison des Mines et des Ponts", in the beautiful Latin Quarter of Paris </mark></h3>
				<h3 class="wow bounceIn" data-wow-delay="1.3s"><mark>9th edition of the Workshop</mark></h3>
				<h1 class="wow fadeInUp" data-wow-delay="1.6s" style="background-color:rgba(242,84,95,0.5);">Performance and Scalability of Storage Systems</h1>
				<a href="#presentation" class="btn btn-lg btn-default smoothScroll wow fadeInUp hidden-xs" data-wow-delay="2.3s">Overview</a>
				<a href="#registration" class="btn btn-lg btn-danger smoothScroll wow fadeInUp" data-wow-delay="2.3s">Register</a>
			</div>


		</div>
	</div>
</section>


<!-- =========================
    OVERVIEW SECTION   
============================== -->
<section id="presentation" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow fadeInUp col-md-6 col-sm-6" data-wow-delay="0.6s">
				<h3>Per3S is a french workshop centered on performances of storage system and all the issues related to storage at scale </h3>
				<p>The terminology used in Per3S for storage includes HPC systems as well as Cloud architectures, the common point between both being scalability. Presentations and talks focus in application, system or architecture. This 7th edition aims to gather during one day researchers from academia and industry, experimented or junior, storage users and customers with the sole purpose to exchange and foster the community.</p>
			</div>
					
			<div class="wow fadeInUp col-md-6 col-sm-6" data-wow-delay="0.9s">
				<img src="images/Design-ohne-Titel-20.png" class="img-responsive" alt="Overview" title="Meet the storage system of the Fastest AI Supercomputer in the world: EOS">
			</div>

		</div>
	</div>
</section>


<!-- =========================
    Call for Poster
============================== -->
<section id="cfp" class="parallax-section">
	<div class="container">
		<div class="row">
			<div class="wow fadeInUp col-md-20 col-sm-20" data-wow-delay="0.6s">

				<h3>Per3S 9th Edition </h3>
                <p> Per3S is a workshop aiming to bring together the scientific and technological storage community to discuss and address issues and challenges associated to performance and data operations at scale. These topics cover HPC storage as well as Cloud-oriented architectures, both sharing the need for extreme scale. </p>
                </p> Per3S fully encourages young researchers to present their work by submitting an abstract. The abstract can relate to an original work, on-going work, with fresh problems/solutions, or one already submitted and/or accepted in an international conference in order to be the subject of discussions. </p>
            <h3> Modality of submissions </h3>
Communications and submissions may be made either in French or in English. </p>

            <h3> Important dates </h3>
            <ul>
            <li> Submission of abstracts from April 15 until May 7th </li>
	    <li> Two paragraph, a short bio and title of the poster to be sent to: <a href="mailto:per3s.contact@gmail.com">per3s.contact@gmail.com</a> </li>
            <li> Notifications are made to authors within 3 days of submission </li>
            <li> Workshop on May 23th </li>
            </ul>
			</div>
		</div>
		</div>
	</div>
</section>


<!-- =========================
    DETAIL SECTION   
============================== -->
<section id="detail" class="parallax-section">
	<div class="container">
		<div class="row">
			<div class="wow fadeInLeft col-md-4 col-sm-4" data-wow-delay="0.3s">
				<i class="fa fa-group"></i>
				<h3>50 Participants</h3>
				<p>Previous editions of Per3S have successfully fostered a community of researchers both from academia and industry working on storage technologies. The audience is around 50 persons.</p>
			</div>

			<div class="wow fadeInUp col-md-4 col-sm-4" data-wow-delay="0.6s">
				<i class="fa fa-clock-o"></i>
				<h3>3 sessions</h3>
				<p>The program is organized around 3 sessions: one dedicated to Cloud, Storage technologies and data management, the second sessions is focused on poster for interactive discussion, and the last and third session is centered on HPC storage technologies and Lustre in particular.</p>
			</div>

			<div class="wow fadeInRight col-md-4 col-sm-4" data-wow-delay="0.9s">
				<i class="fa fa-microphone"></i>
				<h3>12 talks, 8 Posters</h3>
				<p>Each posters is coming with an additional Flash-Presentation. Get within a single day a comprehensive overview of the storage activities in France.</p>
			</div>
		</div>
	</div>
</section>



<!-- =========================
    PROGRAM SECTION   
============================== -->
<section id="programme" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow fadeInUp col-md-12 col-sm-12" data-wow-delay="0.6s">
				<div class="section-title">
					<h2>Program</h2>
					<p>Pers3S workshop spans a full day from 9am to 17h30, with a total of 3 sessions plus two distinguished talks and a concluding panel session:
					 <b>
					 <ul>
						 <li>8h30-9h00 		Participants Welcoming </li>	
						 <li>9h00-11h00 	Cloud and Storage </li>	
						 <li>11h00-11h20 	Break </li>	
						 <li>11h20-12h00 	Young Researchers Distinguished talks </li>	
						 <li>12h30-13h00 	Flash presentations to introduce posters</li>	
						 <li>12h30-14h00	** Lunch and Posters ** </li>	
						 <li>14h00-16h00 	HPC Storage and Lustre </li>	
						 <li>16h00-16h30 	Break </li>	
						 <li>16h30-17h30 	Panel </li>	
						 <li>17h30-20h 	Casual networking at <a href="https://maps.app.goo.gl/7BaetC3nix9dKeWP7"> Le Vin Sobre</a> (2 minutes walk)</li>	
					</ul>
					</b>
					</p>	
				</div>
			</div>

			<div class="wow fadeInUp col-md-10 col-sm-10" data-wow-delay="0.9s">
				<!-- Nav tabs -->
				<ul class="nav nav-tabs" role="tablist">
					<li class="active"><a href="#atscale" aria-controls="atscale" role="tab" data-toggle="tab">Storage at Scale</a></li>
					<li><a href="#distinguished" aria-controls="distinguished" role="tab" data-toggle="tab">Distinguished talks</a></li>
					<li><a href="#flash" aria-controls="flash" role="tab" data-toggle="tab">Flash presentation and Posters</a></li>
					<li><a href="#hpc" aria-controls="hpc" role="tab" data-toggle="tab">HPC and Lustre</a></li>
				</ul>
				<!-- tab panes -->
				<div class="tab-content">
					<div role="tabpanel" class="tab-pane active" id="atscale">
						<h3> 9h-11h00   Cloud and Storage </h3>
                                                <div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/baptiste_lepers.jpg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 9h00 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Design and Implementation of a Fast Persistent Key-Value Store</h2>
							<h3> Baptiste Lepers, INRIA </h3>
							<p> Modern block-addressable NVMe SSDs provide much higher bandwidth and similar performance for random and sequential access. Persistent key-value stores (KVs) designed for earlier storage devices, using either Log-Structured Merge (LSM) or B trees, do not take full advantage of these new devices. Logic to avoid random accesses, expensive operations for keeping data sorted on disk, and synchronization bottlenecks make these KVs CPU-bound on NVMe SSDs.
We present a new persistent KV design. Unlike earlier designs, no attempt is made at sequential access, and data is not sorted when stored on disk. A shared-nothing philosophy is adopted to avoid synchronization overhead. Together with batching of device accesses, these design decisions make for read and write performance close to device bandwidth. Finally, maintaining an inexpensive partial sort in memory produces adequate scan performance.
We implement this design in KVell, the first persistent KV able to utilize modern NVMe SSDs at maximum bandwidth. We compare KVell against available state-of-the-art LSM and B tree KVs, both with synthetic benchmarks and production workloads. KVell achieves throughput at least 2x that of its closest competitor on read-dominated workloads, and 5x on write-dominated workloads. For workloads that contain mostly scans, KVell performs comparably or better than its competitors. KVell provides maximum latencies an order of magnitude lower than the best of its competitors, even on scan-based workloads.</p>
						</div>
						
						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/valentin_honoré.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 9h20 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Bridging the gap between cold and hot storage at scale </h2>
                            				<h3> Valentin Honoré, ENSIEE</h3>
							<p>  Data management at scale is a challenge for both academic and private institutions.  Indeed, large-scale scientific simulation programs require more and more data, in very sophisticated analysis workflows.  For instance, the LHC experiment at CERN is generating 30 PB of data every year, with a total of 100 PB permanently archived.  Mass storage is also central in Cloud infrastructures, that have to deal with EB of data (for instance, Google offers 27 EB of free storage with Gmail).  Such amount of data are stored in dedicated data centers, with two main paradigms: cold storage using magnetic tapes (mass capacity, slow access time) and disks for intermediate to short term storage (so called "hot" data).  Tapes are interfaced with disks throughout dedicated software layers, which do not allow direct access to tapes from computing resources, should they be in a Cloud environment or on computing clusters. Hence, data movement between cold and hot storage becomes more and more critical in the performance of both computing and storage infrastructures.  We present in this talk a roadmap for building a better continuum between cold and hot storage, by deriving new software interactions between the resource management system and the tape systems.  This roadmap expects to be very collaborative, especially with academic and private actors using mass tape storage systems (CEA, Cloud providers etc) </p>
						</div>


						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Alexandru_dobrila.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 9h40 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Scaling a decentralization p2p storage system </h2> 
							<h3> Alexandru Dobrila, HIVENET</h3>
                            				<p> TBA</p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Jana_Toljaga.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 10h00</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> VolipMem: a system-level PMEM Runtime</h2>
							<h3> Jana Toljaga, Institut Polytechnique de Paris </h3>
							<p> Persistent memory (PMEM) offers durability at byte granularity and operates at nearly the speed of volatile memory. While this technology holds great promise for improving performance in large databases and analytics systems, current PMEM runtimes fail to provide a simple interface. This is because developers must manually specify the write set of a failure-atomic block. To avoid the burden of manually specifying the write set, we propose to use low-level hardware features managed by the operating system. To access these features, we isolate the system part of a PMEM runtime, and define three new system primitives: two to define a failure-atomic section and one to recover and map a PMEM in a process. We implemented this interface in VolipMem, which leverages virtualization to expose a page table in a process. We integrated VolipMem into three language runtimes, and evaluated these runtimes with two databases and several libraries. Our results show that VolipMem is both easy to use and efficient.</p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Lydia_AIT_OUCHEGGOU.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 10h20</span> 
								<span><i class="fa fa-map-marker"></i> Amphi Thévenin</span>
							</h6>
							<h2> Bridging Local Efficiency and Global Cost: Two Complementary ICN Caching Strategies </h2>
							<h3> Lydia AIT OUCHEGGOU </h3>
							<p> In-network caching plays a pivotal role in enabling scalable, low-latency data delivery in Information-Centric Networking (ICN). However, as data volumes continue to surge, existing storage infrastructures—especially multi-tiered systems with varying cost and performance characteristics—struggle to keep pace. Meanwhile, critical concerns such as energy efficiency, bandwidth constraints, and Quality of Service (QoS) are often overlooked. Current caching strategies fall into two camps: centralized approaches that optimize local cache performance but neglect network-wide costs, and distributed methods that encourage global coordination but often ignore hardware heterogeneity and fail to enforce fine-grained QoS. To address these challenges, we introduce two complementary solutions. QM-ARC is a centralized, QoS-aware multi-tier adaptive replacement strategy that extends ARC by incorporating application and user priorities through a penalty-based model inspired by Service Level Agreements (SLAs). Complementing this, CL2SM (Cache Less to Save More) is a distributed caching algorithm designed to optimize content placement and replication across multi-tier nodes while minimizing total system cost. It integrates a holistic cost model covering hardware depreciation, bandwidth, energy consumption, and SLA penalties. Together, these strategies offer a unified, intelligent, and cost-effective caching framework tailored for the evolving demands of next-generation ICN.</p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/male_speaker.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 10h40 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2>Title to be announced </h2>
							<h3>TBA </h3>
                            				<p> abstract to be provided </p>
						</div>
						<!-- program divider -->

						<div class="program-divider col-md-12 col-sm-12"></div>
						<div class="col-md-2 col-sm-2">
							<img src="images/coffee_small.png" class="img-responsive" alt="program">
                        			</div>
						<div class="col-md-10 col-sm-10">
						<h6>
							<span><i class="fa fa-clock-o"></i> 11h00 </span> 
						</h6>
							<h4> ** 20 minute break **</h4>
                        			</div>
					</div>

					<div role="tabpanel" class="tab-pane" id="distinguished">
						<!-- program speaker here -->
						<h3> 11h20-12h00 Young Researchers Distinguished Talks</h3>
						<div class="col-md-2 col-sm-2">
							<img src="images/Louis-Marie-Nicolas.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 11h20</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2>DVFS for HPC I/O optimization: a Microbenchmarking Approach</h2>
							<h3> Louis-Marie Nicolas, ATOS/EVIDEN </h3>
							<p> Abstract to be provided </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Catherine_Guelque.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 11h40</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Pallas: a generic trace format for large HPC trace analysis</h2>
							<h3> Catherine Guelque, TelecomSudParis </h3>
							<p> Identifying performance bottlenecks in a parallel application is tedious, especially because it requires analyzing the behaviour of various software components, as bottlenecks may have several causes and symptoms. For example, a load imbalance may cause long MPI waiting times, or contention on disk may degrade the performance of I/O operations. Detecting a performance problem means investigating the execution of an application and applying several performance analysis techniques. To do so, one can use a tracing tool to collect information describing the behaviour of the application. Tracing applications may alter the performance of the application, and can create thousands of heavy trace files, especially at a large scale. Most importantly, the post-mortem analysis needs to load these thousands of trace files in memory, and process them. This quickly becomes impractical for large scale applications, as memory gets exhausted and the number of opened files exceeds the system capacity.
We propose PALLAS, a generic trace format tailored for conducting various post-mortem performance analysis of traces describing large executions of HPC applications. During the execution of the application, PALLAS collects events and detects their repetitions on-the-fly. When storing the trace to disk, PALLAS groups the data from similar events or groups of events together in order to later speed up trace reading. We demonstrate that the PALLAS online detection of the program structure does not significantly degrade the performance of the applications. Moreover, the PALLAS format allows faster trace analysis compared to other evaluated trace formats. Overall, the PALLAS trace format allows an interactive analysis of a trace that is required when a user investigates a performance problem.</p> 
						</div>
					</div>

					<div role="tabpanel" class="tab-pane" id="flash">
						<!-- program speaker here -->
						<h3> 12h-12h30 Flash presentations poster introduction</h3>
						<div class="col-md-2 col-sm-2">
							<img src="images/Meline-trochon.jpg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h00</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Characterization of IO interferences</h2>
							<h3> Méline Trochon, INRIA / DDN </h3>
							<p> Abstract to be provided </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/meriem_bouzouad.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h05</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Adaptive Layer Compression and Storage with QoS-Aware loading for LLM Serving</h2>
							<h3> Meriem BOUZOUAD, ENSTA </h3>
							<p> Today, large language models have demonstrated their strengths in various tasks ranging from reasoning, code generation or complex problem solving. However, this advancement comes with high computational cost, and requires considerable memory to store the model parameters and request context, making it challenging to deploy these models on edge devices to ensure real-time responses and data privacy.  The rise of edge accelerators has significantly boosted on-device processing capabilities; however, memory is still a major bottleneck, a problem that is especially significant in large language models with high memory requirements, when it is unclear whether using all model layers is crucial for maintaining generation quality. In addition to that, the varying workloads on edge devices call for an adaptive solution for the efficient utilization of hardware resources. In this paper, we propose a flexible layer-wise compression approach that produces multiple model variants. Our solution leverages a smart storage mechanism to ensure efficient storage and rapid loading of the most appropriate variant tailored to the Quality of Service (QoS) requirements and the dynamic workload of the system. </p> 
						</div>
						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/female_speaker.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h10</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Tracing-Based I/O Diagnosis for Performance Optimization of Software-Defined Storage Systems </h2>
							<h3> Lina Sadi and Islam Kedadsa</h3>
							<p> Software-Defined Storage (SDS) is gaining traction in edge environments due to its adaptability and decoupling from hardware constraints. However, characterizing and optimizing SDS performance remains challenging, particularly in resource-constrained systems. In this work, we present a systematic tracing-based methodology for detecting and analyzing I/O performance bottlenecks across the Linux storage stack—from the block layer down to device-level interactions. By leveraging low-level tracers, we trace I/O operations to identify the root causes of performance degradation, such as disk queuing delays and write amplification. By simulating diverse I/O workloads, we collect trace data that helps pinpoint specific issues such as throughput degradation, latency spikes, and inefficient I/O patterns. Based on the insights gathered, we propose corrective optimization strategies at the OS level, such as dynamic I/O throttling, aimed at mitigating the identified bottlenecks. Using a Ceph-based deployment as a case study, we aim to demonstrate how our methodology can be applied to effectively diagnose performance issues in near real-time and propose actionable solutions to enhance storage efficiency and maintain stable performance in edge computing environments.</p> 
						</div>
						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/hocine_mahni.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h15</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> FABME: File-Level Placement Policy with Admission Control, Burst Prefetching, and Multi-Criteria Eviction for HPC Multi-Tier Storage</h2>
							<h3> Hocine Mahni </h3>
							<p> High-performance computing (HPC) installations usually front a large-capacity HDD tier with a limited, low-latency SSD tier.
Data migration is driven by Hierarchical Storage Management (HSM) software such as the Robinhood Policy Engine, which operates strictly at file granularity. This constraint prevents direct reuse of the many block-level cache algorithms proposed in the literature.
Our previous multi-criteria replacement policy, MC-ARC, showed that combining recency, frequency, predicted lifetime and user fairness at file scope can outperform classical block caches. Analysis of production traces nevertheless uncovered three recurring pathologies:
(P1) cache pollution by very large or rarely used files;
(P2) post-burst persistence of files whose references occur in short, periodic I/O bursts;
(P3) thrashing when several large files alternate and collectively overflow SSD capacity.
We introduce FABME—a new file-level placement policy that preserves MC-ARC’s multi-criteria spirit while explicitly addressing P1–P3. Running fully on-line and relying solely on metadata already captured by Robinhood changelogs, FABME fuses three components:
Admission control: on every miss, the policy decides whether to admit the file to SSD or confine it to HDD, using file size, access density, inactivity window, and a benefit–cost estimate;
Burst-aware prefetch and eviction: a lightweight detector predicts periodic bursts, triggers just-in-time prefetching, and schedules early eviction to avoid post-burst pollution;
MC-ARC multi-criteria eviction: for admissible files, the final victim is selected with the original recency–frequency–lifetime–fairness score.
Ongoing experiments on Yombo, Synthesized Google I/O Traces and IBM ObjectStoreTrace, executed with our open two-tier simulator, will report hit rate, trace-processing time and migration overhead. </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/male_speaker.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h20</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h3> Title to be announced </h3>
							<h3> TBA </h3>
							<p> Abstract to be provided </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/female_speaker.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 12h25</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h3> Title to be announced </h3>
							<h4> TBA </h4>
							<p> abstract to be provided </p>
						</div>

						<!-- program divider -->

						<div class="program-divider col-md-12 col-sm-12"></div>
						<div class="col-md-2 col-sm-2">
							<img src="images/lunch-icon.png" class="img-responsive" alt="program">
                        			</div>
						<div class="col-md-10 col-sm-10">
						<h6>
							<span><i class="fa fa-clock-o"></i> 12h30 </span> 
						</h6>
							<h4> ** 90 minute lunch break **</h4>
                        			</div>
					</div>

					<div role="tabpanel" class="tab-pane" id="hpc">
						<h3> 14h00-16h00 HPC and Lustre </h3>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/sebastien_buisson.jpg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 14h00</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session </span>
							</h6>
							<h2>Lustre: status and path forward </h2>
							<h3>Sebastien Buisson, Whamcloud</h3>
							<p> Lustre is the leading open-source and open-development file system for HPC. Around two thirds of the top 100 supercomputers use Lustre. It is a community developed technology with contributors from around the world. Lustre currently supports many HPC infrastructures beyond scientific research, such as financial services, energy, manufacturing, and life sciences and in recent years has been leveraged by cloud solutions to bring its performance benefits to a variety of new use cases (particularly relating to AI). This talk will reflect on the current state of the Lustre ecosystem and also will include the latest news relating to Lustre community releases (LTS releases and major releases), the roadmap, and details of features under development.</p>
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Philippe_couvee.jpg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 14h20</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Ephemeral IO services </h2>
							<h3>  Philippe Couvée, EVIDEN </h3>
							<p> Ephemeral IO services, explored in the IO-SEA project, and being extended in the EUPEX project, help data intensive HPC workflows minimizing data movements, keeping active data close to compute nodes for their entire durations, and isolating IO intensive steps from other applications sharing the same file systems. They range from workflows-dedicated parallel file systems to Burst Buffers and more specific object storage services. They run on dedicated hardware resources.

In this talk, we will introduce the main concepts, the intitial user interfaces and performance results, and discuss the challenges still to be addressed to make it a mainstream solution. </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/salem_el_sayed.jpeg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 14h40</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Exabyte for ExaScale and other storage systems </h2>
							<h3> An overview of Juelich Supercomputing Centre Storage landscape </h3>
							<h3> Salem el Sayed, ForschungsZentrum Jülich </h3>
							<p> In 2024, the Juelich Supercomputing Centre successfully deployed the sixth iteration of its central storage system, JUelich STorage (JUST)6, a 154 PiB disk storage system based on IBM's Storage Scale System 6000. This milestone was achieved after migrating over 32 PiB of data to the new infrastructure. The Centre is now expanding its storage capabilities with the deployment of the 300 PiB disk-based ExaSTORE and 29 PiB NVMe-based ExaFLASH systems, both designed to support the upcoming Exascale system JUPITER. This presentation will provide an overview of the Juelich storage landscape, highlighting the challenges and strategies for deploying, migrating, and maintaining complex storage infrastructures at scale.  </p> 
						</div>


						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>

						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/matthieu_dorier.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 15h00</span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Ten years of Mochi data services for HPC: a retrospective</h2>
							<h3> Matthieu Dorier, Argonne National Laboratory </h3>
							<p> Over the last 10 years, the Mochi project has explored the notion of composition to foster research and development of HPC data services. Adopted by an increasing number of international users, its collection of components and its methodology allow for rapid development of new data services tailored to specific use cases and applications. In this talk we will look back on this decade of research in and around Mochi, providing a critical retrospective with lessons learned and perspectives for the future of HPC data service research. </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/male_speaker.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 15h20 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Phobos Parallel Heterogenous OBject Store</h2>
							<h3> Gauthier Evraerd, CEA/DAM </h3>
                            				<p> Phobos, standing for Parallel Heterogeneous OBject Store, is a software designed to handle large volumes of data across different storage technologies. It was firstly designed to manage tape storage, thus offering tape lifecycle features such as repack, but is also able to store data on POSIX and RADOS systems, which can be used as cache systems before tape archival. Multiple interfaces were developped to use Phobos as an HSM-end backend, like Lustre and iRODS. This presentation will update the current status of Phobos development and detail some new features like the object copy management.</p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/Luan_Teylo.png" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 15h40 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> A Deep Look Into the Temporal I/O Behavior of HPC Applications </h2>
							<h3> Luan Teylo, INRIA </h3>
							<p> The increasing gap between compute and I/O speeds in high-performance computing (HPC) systems imposes the need for techniques to improve applications’ I/O performance. Such techniques must rely on assumptions about I/O behavior in order to efficiently allocate I/O resources such as burst buffers, to schedule accesses to the shared parallel file system or to delay certain applications at the batch scheduler level to prevent contention, for instance. In this paper, we verify these common assumptions about I/O behavior, specifically about temporal behavior, using over 440,000 traces from real HPC systems. By combining traces from diverse systems, we characterize the behaviors observed in real HPC workloads. Among other findings, we show that I/O activity tends to last for a few seconds, and that periodic jobs are the minority, but responsible for a large portion of the I/O time. Furthermore, we make projections for the expected improvement yielded by popular approaches for I/O performance improvement. Our work provides valuable insights to everyone working to alleviate the I/O bottleneck in HPC. </p> 
						</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<div class="col-md-2 col-sm-2">
							<img src="images/coffee_small.png" class="img-responsive" alt="program">
                        			</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 16h00-16h30 </span> 
							</h6>
							<h4> ** 30 minute break **</h4>
                        			</div>

						<!-- program divider -->
						<div class="program-divider col-md-12 col-sm-12"></div>
						<!-- program speaker here -->
						<div class="col-md-2 col-sm-2">
							<img src="images/panel.jpg" class="img-responsive" alt="program">
						</div>
						<div class="col-md-10 col-sm-10">
							<h6>
								<span><i class="fa fa-clock-o"></i> 16h30-17h30 </span> 
								<span><i class="fa fa-map-marker"></i> Plenary Session</span>
							</h6>
							<h2> Panel discussion </h2>
							<h3> Trends in I/O and Storage </h3>
						</div>
			</div>
		</div>
	</div>
</section>



<!-- =========================
    Committee SECTION   
============================== -->
<section id="organisateurs" class="parallax-section">
	<div class="container">
		<div class="row">
				<div class="section-title">
					<h2>Steering Committee</h2>
					<p>Since its inception 8 years ago, Per3S is managed by a steering committee, the committee is fluid and tends to evolve from an edition to the other.</p>
				</div>
			</div>

			<!-- Testimonial Owl Carousel section
			================================================== -->
			<div id="owl-speakers" class="owl-carousel">

				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/Francois.png" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>François Trahay</h3>
								<h6>Télécom SudParis / Institut Polytechnique de Paris</h6>
François Trahay is full professor at Télécom SudParis since 2011. He received his Ph.D. degree in computer science from the University of Bordeaux in 2009. He has been working on runtime systems for high performance computing since 2006. His research interests now mostly focus on performance analysis for HPC and distributed systems. He is the project leader and main developer of the EZTrace framework for performance analysis. 
							</div>
					</div>
				</div>
				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/Jalil.jpg" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>Jalil Boukhobza </h3>
								<h6>ENSTA</h6>
								Jalil Boukhobza is Professor at the ENSTA, a French State Graduate, Post-Graduate and Research Institute part of Institut Polytechnique de Paris. His main research interests include storage system design, performance evaluation and energy optimization, and operating system design. He works on different application domains such as embedded systems, cloud computing, and database systems.
							</div>
					</div>
				</div>
				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/shadi_ibrahim.png" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>Shadi Ibrahim </h3>
								<h6>Inria - Bretagne</h6>
                                Shadi Ibrahim is a Research Scientist at Inria. He obtained his Ph.D. degree in Computer Science from Huazhong University of Science and Technology (HUST) in Wuhan of China in 2011. His current research interests are in scalable data management, storage systems, data-intensive computing, parallel I/O and distributed file systems, virtualization technology and Cloud/Fog computing. Dr. Ibrahim received in 2020 the IEEE TCSC Award for Excellence in Scalable Computing (Middle Career Researcher), he's a Distinguished member of the ACM and a Senior member of IEEE.
							</div>
					</div>
				</div>

				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/philippe_deniel.jpeg" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>Philippe Deniel</h3>
								<h6>CEA-DAM</h6>
								Philippe Deniel is heading the Storage Architecture and Systems Lab at CEA/DIF. His lab is in charge of managing the daily data production of both CEA/DIF data centers namely Tera and TGCC.  Attentionality to manage daily production, the lab is also developing actively Lustre and HPSS. Philippe is the original developer of NFS-Ganesha an open-source NFS server in user space available in LGPLv3. Philippe is the Technical Coordinator the EuroHPC <a href="https://iosea-project.eu">IO-Sea project</a>.
							</div>
					</div>
				</div>
				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/philippe_raipin.jpeg" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>Philippe Raipin</h3>
								<h6>Orange Labs</h6>
								Philippe is a Research Program Manager at Orange Labs, where is overseeing the activity on the Web of Things Platform.
							</div>
					</div>
				</div>
				<div class="item wow fadeInUp col-md-3 col-sm-3" data-wow-delay="0.6s">
					<div class="speakers-wrapper">
						<img src="images/jt.png" class="img-responsive" alt="speakers">
							<div class="speakers-thumb">
								<h3>Jean-Thomas Acquaviva</h3>
								<h6>DDN Storage</h6>
Jean-Thomas successively worked for Intel, the University of Versailles and the French Atomic Commission (CEA). He participated to the creation of their joint laboratory on Exascale Research. At DDN, Jean-Thomas' role includes overseeing research collaborations in Europe as well as product management for some advanced DDN’s solutions. 
							</div>
					</div>
				</div>
			</div>

		</div>
	</div>
</section>

<!-- =========================
   REGISTER SECTION   
============================== -->
<section id="registration" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow fadeInUp col-md-7 col-sm-7" data-wow-delay="0.6s">
				<h2> <a href="https://forms.gle/Gii9QoWskLoKaGqb6">Click here to register</a> </h2>.
				<h3>Per3S is an free-access event however for logistic purpose a registration is kindly requested. Access to the site may require the presentation of an ID.</h3>
				<p>Provided email addresses will only be used to contact participant for logistic purpose or broadcast last minute changes. The emails addresses will not be kept after the Workshop (GDPR).</p>
			</div>

			<!--
			<div class="wow fadeInUp col-md-5 col-sm-5" data-wow-delay="1s">
				<embed src="https://forms.gle/Gii9QoWskLoKaGqb6" width="440" height="310" frameborder="0" marginheight="0" marginwidth="0"></embed>
			-->
			</div>
			<div class="col-md-1"></div>
		</div>
	</div>
</section>

<!-- =========================
    VENUE SECTION   
============================== -->
<section id="venir" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow fadeInLeft col-md-offset-1 col-md-5 col-sm-8" data-wow-delay="0.9s">
				<h2>Venue</h2>
			<p>The workshop will be held in <a href="http://www.maisondesmines.com"> La Maison des Mines et des Ponts </a>, a building of the prestigious Ecole des Mines et des Ponts, at the heart of the Latin quarter on the left bank of Paris.</p>
				<h4><a href="http://www.maisondesmines.com"> Maison des Mines et des Ponts </a></h4>
  				<h4>270 rue Saint Jacques</h4>
  				<h4>75005 Paris</h4>
				<h4>In case of issue Jean-Thomas: 06 15 95 63 06</h4>		
				<h4> <a href="http://www.maisondesmines.com/contact">Access map</a> </h4>
			</div>

		</div>
	</div>
</section>


<!-- =========================
    SPONSORS SECTION   
============================== -->
<section id="sponsors" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow bounceIn col-md-9 col-sm-9">
				<div class="section-title">
					<h2>Sponsors</h2>
					<p>Per3S would like to warmly thanks its sponsors: </p>
				</div>
			</div>

			<div class="wow fadeInUp col-md-offset-0 col-md-4 col-sm-4 col-xs-4" data-wow-delay="0.3s">
				<a href="https://ddn.com">
					<img src="images/FR2030_Cloud_Couleur.png" class="img-responsive" title="DataDirect Networks (DDN) is the world’s leading big data storage supplier to data-intensive, global organizations" alt="https://ddn.com">
			</div>
			<div class="wow fadeInUp col-md-offset-0 col-md-4 col-sm-4 col-xs-4" data-wow-delay="0.3s">
				<a href="https://ddn.com">
					<img src="images/logo_numex.png" class="img-responsive" title="DataDirect Networks (DDN) is the world’s leading big data storage supplier to data-intensive, global organizations" alt="https://ddn.com">
			</div>
			<div class="wow fadeInUp col-md-offset-0 col-md-4 col-sm-4 col-xs-4" data-wow-delay="0.3s">
				<a href="https://ddn.com">
					<img src="images/DDN-Logo-Landscape-RGB.png" class="img-responsive" title="DataDirect Networks (DDN) is the world’s leading big data storage supplier to data-intensive, global organizations" alt="https://ddn.com">
			</div>
			<div class="wow fadeInUp col-md-4 col-sm-3 col-xs-4" data-wow-delay="0.6s">
				<a href="https://u-paris.fr">
				<img src="images/Universite_Paris-Cite-logo.jpeg" class="img-responsive" title="Data Intensive and Knowledge Oriented Systems (diNo)">
			</div>
			<div class="wow fadeInUp col-md-4 col-sm-3 col-xs-4" data-wow-delay="0.6s">
				<a href="https://www.ensta-bretagne.fr">
				<img src="images/ENSTA-Bretagne-large.png" class="img-responsive" title="ENSTA Bretagne est l’école d’ingénieurs pour l’innovation dans le secteur maritime, la défense, les transports/mobilité, l’aérospatiale et les technologies numériques.">
			</div>

			<!--	<div class="wow fadeInUp col-md-3 col-sm-6 col-xs-6" data-wow-delay="0.9s">
				<img src="images/cea.png" class="img-responsive" alt="sponsors">	
			</div>
			-->
		</div>
	</div>
</section>


<!-- =========================
    CONTACT SECTION   
============================== -->
<section id="contact" class="parallax-section">
	<div class="container">
		<div class="row">

			<div class="wow fadeInUp col-md-offset-1 col-md-5 col-sm-6" data-wow-delay="0.6s">
				<div class="contact_des">
					<h3>Past Editions </h3>
					<p>The last tree editions of PER3S are available at the following addresses.</p>
					<a href="https://per3s.github.io/per3s.2024/" class="btn btn-danger">8th edition: 2024</a>
					<a href="https://per3s.github.io/per3s.2023/" class="btn btn-danger">7th edition: 2023</a>
					<a href="https://per3s.github.io/per3s.2022/" class="btn btn-danger">6th edition: 2022</a>
				</div>
			</div>
			<!--
			<div class="wow fadeInUp col-md-5 col-sm-6" data-wow-delay="0.9s">
				<div class="contact_detail">
					<div class="section-title">
						<h2>S'inscrire à la mailing list Per3S</h2>
						<div class="container" id="ff-compose"></div>
					<form action="#" method="post" id="contact-form">
						<input name="name" type="text" class="form-control" id="name" placeholder="Nom">
					  	<input name="message" rows="5" class="form-control" id="message" placeholder="Organisation">
					  	<input name="email" type="email" class="form-control" id="email" placeholder="Email">
						<div class="col-md-6 col-sm-10">
							<div class="form-group mb-4">
								<div id="Result-message" class="alert alert-success d-none">Send result message will display here </div>
							</div>
							<input name="submit" type="submit" class="form-control" id="submit" value="Inscription">
						</div>
					</form>
				</div>
			</div>
			-->
		</div>
	</div>
</section>


<!-- Back top -->
<a href="#back-top" class="go-top"><i class="fa fa-angle-up"></i></a>


<!-- =========================
     SCRIPTS   
============================== -->
<!-- <script src="js/jquery.min.js"></script> -->
<script src="js/jquery.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.parallax.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/smoothscroll.js"></script>
<script src="js/wow.min.js"></script>
<script src="js/custom.js"></script>
<script src="js/send-email-ajax.js"></script>

</body>
</html>
